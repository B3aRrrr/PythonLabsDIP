{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучить готовую сеть\n",
        "2. Прунить её \n",
        "3. To .onnx file format\n",
        "4. "
      ],
      "metadata": {
        "id": "SRxio22-cjG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnx_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmqlfpYge6N",
        "outputId": "70e92fa0-4d3b-4aff-8149-af848847bcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx_tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from onnx_tf) (6.0)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons->onnx_tf) (23.0)\n",
            "Installing collected packages: typeguard, onnx, tensorflow-addons, onnx_tf\n",
            "Successfully installed onnx-1.13.1 onnx_tf-1.10.0 tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "zKBYJiI9fCve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# CIFAR10 dataset consists of 50K training images. We define the batch size of 10 to load 5,000 batches of images.\n",
        "batch_size = 10\n",
        "number_of_labels = 10 \n",
        "\n",
        "# Create an instance for training. \n",
        "# When we run this code for the first time, the CIFAR10 train dataset will be downloaded locally. \n",
        "train_set =CIFAR10(root=\"./data\",train=True,transform=transformations,download=True)\n",
        "\n",
        "# Create a loader for the training set which will read the data within batch size and put into memory.\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
        "\n",
        "# Create an instance for testing, note that train is set to False.\n",
        "# When we run this code for the first time, the CIFAR10 test dataset will be downloaded locally. \n",
        "test_set = CIFAR10(root=\"./data\", train=False, transform=transformations, download=True)\n",
        "\n",
        "# Create a loader for the test set which will read the data within batch size and put into memory. \n",
        "# Note that each shuffle is set to false for the test loader.\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
        "\n",
        "print(\"The number of batches per epoch is: \", len(train_loader))\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYvar8MMfn3d",
        "outputId": "4dd721e2-1d09-46fc-861d-dd22ba610c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "The number of images in a training set is:  50000\n",
            "Files already downloaded and verified\n",
            "The number of images in a test set is:  10000\n",
            "The number of batches per epoch is:  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a convolution neural network\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(24)\n",
        "        self.fc1 = nn.Linear(24*10*10, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.bn1(self.conv1(input)))      \n",
        "        output = F.relu(self.bn2(self.conv2(output)))     \n",
        "        output = self.pool(output)                        \n",
        "        output = F.relu(self.bn4(self.conv4(output)))     \n",
        "        output = F.relu(self.bn5(self.conv5(output)))     \n",
        "        output = output.view(-1, 24*10*10)\n",
        "        output = self.fc1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./myFirstModel.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy():\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "\n",
        "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            \n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1,000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 1000 == 999:    \n",
        "                # print every 1000 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
        "        accuracy = testAccuracy()\n",
        "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy\n",
        "\n",
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(test_loader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "  \n",
        "    # Let's see what if the model identifiers the  labels of those example\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "BclKQ5esdS9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a neural network model \n",
        "model = Network()\n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "# Let's build our model\n",
        "train(5)\n",
        "print('Finished Training')\n",
        "\n",
        "# Test which classes performed well\n",
        "# testModelAccuracy()\n",
        "\n",
        "# Let's load the model we just created and test the accuracy per label\n",
        "model = Network()\n",
        "path = \"myFirstModel.pth\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# Test with batch of images\n",
        "testBatch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "E4w-yclBeNbv",
        "outputId": "7628d901-2884-4496-a439-1387f677d9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cpu device\n",
            "[1,  1000] loss: 1.767\n",
            "[1,  2000] loss: 1.450\n",
            "[1,  3000] loss: 1.302\n",
            "[1,  4000] loss: 1.202\n",
            "[1,  5000] loss: 1.138\n",
            "For epoch 1 the test accuracy over the whole test set is 62 %\n",
            "[2,  1000] loss: 1.075\n",
            "[2,  2000] loss: 1.032\n",
            "[2,  3000] loss: 0.993\n",
            "[2,  4000] loss: 0.992\n",
            "[2,  5000] loss: 0.961\n",
            "For epoch 2 the test accuracy over the whole test set is 65 %\n",
            "[3,  1000] loss: 0.885\n",
            "[3,  2000] loss: 0.889\n",
            "[3,  3000] loss: 0.888\n",
            "[3,  4000] loss: 0.892\n",
            "[3,  5000] loss: 0.862\n",
            "For epoch 3 the test accuracy over the whole test set is 67 %\n",
            "[4,  1000] loss: 0.776\n",
            "[4,  2000] loss: 0.813\n",
            "[4,  3000] loss: 0.809\n",
            "[4,  4000] loss: 0.823\n",
            "[4,  5000] loss: 0.833\n",
            "For epoch 4 the test accuracy over the whole test set is 68 %\n",
            "[5,  1000] loss: 0.725\n",
            "[5,  2000] loss: 0.732\n",
            "[5,  3000] loss: 0.758\n",
            "[5,  4000] loss: 0.755\n",
            "[5,  5000] loss: 0.775\n",
            "For epoch 5 the test accuracy over the whole test set is 70 %\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fc652fc7301b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Test which classes performed well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtestModelAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Let's load the model we just created and test the accuracy per label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'testModelAccuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SduTsU_ZcPTX"
      },
      "outputs": [],
      "source": [
        "import torch.onnx \n",
        "\n",
        "#Function to Convert to ONNX \n",
        "def Convert_ONNX(path:str=\"myFirstModel.pth\"): \n",
        "\n",
        "    model = Network()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    # set the model to inference mode \n",
        "    model.eval() \n",
        "\n",
        "    # Let's create a dummy input tensor  \n",
        "    dummy_input = torch.randn((1,3,32,32), requires_grad=True)  \n",
        "\n",
        "    # Export the model   \n",
        "    torch.onnx.export(model,         # model being run \n",
        "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
        "         \"ImageClassifier.onnx\",       # where to save the model  \n",
        "         export_params=True,  # store the trained parameter weights inside the model file \n",
        "         opset_version=10,    # the ONNX version to export the model to \n",
        "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
        "         input_names = ['modelInput'],   # the model's input names \n",
        "         output_names = ['modelOutput'], # the model's output names \n",
        "         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n",
        "                                'modelOutput' : {0 : 'batch_size'}}) \n",
        "    print(\" \") \n",
        "    print('Model has been converted to ONNX') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/myFirstModel.pth\"\n",
        "Convert_ONNX(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgcFMfKghJjE",
        "outputId": "680804e8-058d-4c0f-df1f-4ceb771eaa09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            " \n",
            "Model has been converted to ONNX\n"
          ]
        }
      ]
    }
  ]
}